{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting pubmed data with the help of python\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/aaekay/Resources/blob/main/tools/extracting_pubmed_data.ipynb)\n",
    "\n",
    "You can follow this code and use it to extract information about the article "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two methods by which you can extract information\n",
    "1. its an easy method where the python will read the pubmed url with the help of html and you can pick up which information you want to select for it\n",
    "2. it is a more advanced method which used pubmed api and query method\n",
    "\n",
    "Let's dive in the first method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Lengthy method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the pmid csv file already provided with the repositroy for which we want to extract information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first install the below library\n",
    "!pip install bs4\n",
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now import the relevant libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now dowload the file from the repository\n",
    "#!wget = https://github.com/aaekay/Resources/tools/pmid.csv\n",
    "pmids = pd.read_csv(\"~/Documents/pmid.csv\", header =None )\n",
    "pmid_list = pmids[0].to_list()\n",
    "pmid_list  = [str(pmid) for pmid in pmid_list]\n",
    "out = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the loop which will iteratre  over each pubmed id and retrieve articles\n",
    "for pmid in pmid_list:\n",
    "    url = 'https://pubmed.ncbi.nlm.nih.gov/'+ pmid\n",
    "    response2 = requests.get(url)\n",
    "    soup2 = BeautifulSoup(response2.content, 'html.parser')\n",
    "\n",
    "    title = soup2.select('h1.heading-title')[0].text.strip()\n",
    "        \n",
    "    data = {'title': title, 'pmid': pmid}\n",
    "    time.sleep(3)\n",
    "    out.append(data)\n",
    "df = pd.DataFrame(out)\n",
    "# after retreiving it will create an excel file\n",
    "df.to_excel('my_results.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can make a function and use it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pubex(pmids, titles = None, dois = None):\n",
    "    from bs4 import BeautifulSoup\n",
    "    import csv\n",
    "    import time\n",
    "    import requests\n",
    "    import pandas as pd\n",
    "    pmids_df = pd.read_csv(pmids, header =None )\n",
    "    pmid_list = pmids_df[0].to_list()\n",
    "    pmid_list_str  = [str(pmid) for pmid in pmid_list]\n",
    "    out = []\n",
    "    for pmid in pmid_list_str:\n",
    "        url = 'https://pubmed.ncbi.nlm.nih.gov/'+ pmid\n",
    "        response2 = requests.get(url)\n",
    "        soup2 = BeautifulSoup(response2.content, 'html.parser')\n",
    "        if titles == \"True\" and dois == \"True\" :\n",
    "            doi = soup2.select('a.id-link')[0].text.strip()\n",
    "            title = soup2.select('h1.heading-title')[0].text.strip()\n",
    "            data = {'title': title, 'pmid': pmid, 'doi':doi}\n",
    "        if titles == \"True\" and dois is None:\n",
    "            title = soup2.select('h1.heading-title')[0].text.strip()\n",
    "            data = {'title': title, 'pmid': pmid}\n",
    "        time.sleep(3)\n",
    "        out.append(data)\n",
    "        df = pd.DataFrame(out)\n",
    "    df.to_excel('my_results.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pubex(\"C:/Users/mitug/Downloads/founder_pmid.csv\", titles = \"True\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pubmed-parser\n",
    "## uncomment the above command and run it to install the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pubmed_parser as pp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will store all the pmids which we want to retreive with the help of excel and pandas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmid = pd.read_csv(\"pmid.csv\", header =None )\n",
    "pmid = pmid[0].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2532/2939644789.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpmid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "pmid[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, NoneType found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2532/1261327367.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdict_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_xml_web\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpmid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m19\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_xml\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict_out\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"title\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\pubmed_parser\\pubmed_web_parser.py\u001b[0m in \u001b[0;36mparse_xml_web\u001b[1;34m(pmid, sleep, save_xml)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \"\"\"\n\u001b[0;32m    192\u001b[0m     \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_xml\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpmid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msleep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m     \u001b[0mdict_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse_pubmed_web_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m     \u001b[0mdict_out\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"pmid\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpmid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msave_xml\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\pubmed_parser\\pubmed_web_parser.py\u001b[0m in \u001b[0;36mparse_pubmed_web_tree\u001b[1;34m(tree)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \"\"\"\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"//articletitle\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[0mtitle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtitle\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"//articletitle\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"//booktitle\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mtitle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtitle\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"//booktitle\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: sequence item 0: expected str instance, NoneType found"
     ]
    }
   ],
   "source": [
    "dict_out = pp.parse_xml_web(pmid[19], save_xml=False)\n",
    "title.append(dict_out[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "227872fd7638373db33c371d97be9b40a3c2203559e72894ef81c1759e881a0a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
